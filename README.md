# NLP-class-Emines-Jan22
Repository for a one-week NLP class given In January 2022 for the Data Science Specialty @ [Emines, Mohammed VI University, Ben Guerir, Morocco](https://www.emines-ingenieur.org/). 

## Slides: 
* [Day 1: Introduction, Text Processing, word embeddings models](https://drive.google.com/file/d/1ACGT53WHtDm6H5SKZoOwN_ww7NZtQn66/view?usp=sharing)
* [Day 2: Recurrent Neural Networks, Application to Text Classification](https://drive.google.com/file/d/1ACGT53WHtDm6H5SKZoOwN_ww7NZtQn66/view?usp=sharing)
* [Day 3: Language Models, Natural Language Generation, Evaluation Metrics](https://drive.google.com/file/d/1ACGT53WHtDm6H5SKZoOwN_ww7NZtQn66/view?usp=sharing)
* [Day 4: Sequence to Sequence Models with Attention, Transformers - Application to Machine Translation](https://drive.google.com/file/d/1ACGT53WHtDm6H5SKZoOwN_ww7NZtQn66/view?usp=sharing)
* [Day 5: Pretrained Language Systems, Transfer Learning in NLP](https://drive.google.com/file/d/1ACGT53WHtDm6H5SKZoOwN_ww7NZtQn66/view?usp=sharing)

## Practical Exercises
* [Day 1: Exploring Text preprocessing techniques and word embeddings models](https://colab.research.google.com/drive/1xATgl-D-pt8cXULqkffOVBxqUPjLQkLa?usp=sharing)
* [Day 2: Building a sentiment analysis classifier with a RNN on the Stanford Sentiment Treebank dataset](https://colab.research.google.com/drive/1elBdCGOLGYqL8xf8GvtqdKopv1coisT-?usp=sharing)
* [Day 3: Training a RNN Language Model on the ROC Stories dataset](https://colab.research.google.com/drive/1elBdCGOLGYqL8xf8GvtqdKopv1coisT-?usp=sharing)
* [Day 4: Build an end-to-end French-English Machine Translation System](https://colab.research.google.com/drive/1elBdCGOLGYqL8xf8GvtqdKopv1coisT-?usp=sharing)
* [Day 5: Generating Text with pretrained Language Models](https://colab.research.google.com/drive/1elBdCGOLGYqL8xf8GvtqdKopv1coisT-?usp=sharing)
* [Evaluated Exercises](https://colab.research.google.com/drive/1A8n1uIIwvP_u5zxpgTO256akmXZiuPeY?usp=sharing)

## Reading activities
* **Day 1**: 
  1. [GloVe embedding model](https://nlp.stanford.edu/pubs/glove.pdf)
  2. Overview of word embeddings models: [1](https://ruder.io/word-embeddings-1/) + [2](https://ruder.io/word-embeddings-softmax/index.html)

* **Day 2**: 
   1. [Recap on RNNs](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)
   2. [Understand LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs)
   3. [Backpropagation through time for training LSTMs](https://d2l.a[i/chapter_recurrent-neural-networks/bptt.html)

* **Day 3**: 
    1. [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
    2. [The curious case of text degeneration](https://arxiv.org/pdf/1904.09751.pdf)
    3. [Evaluation Metrics for Language Models](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/)

* **Day 4**: 
  1. [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
  2. [Visual Attention - Show, Attend and Tell](https://arxiv.org/pdf/1502.03044.pdf)

* **Day 5**: 
  1. [The Transformer XL - Learning Cross-Lingual embeddings](https://arxiv.org/pdf/1901.07291.pdf)
  2. Using BERT for topic modelling: [1](https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6) + [2](https://arxiv.org/pdf/2008.09470.pdf)
  
## Additional ressources: 
* [Stanford NLP class](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)
* [Textbook - A primer on Neural Networks for Natural Language Processing (2015)](https://u.cs.biu.ac.il/~yogo/nnlp.pdf)
* [Textbook - Speech and Language Processing (2021)](https://web.stanford.edu/~jurafsky/slp3/)
* [Hugging face course on pretrained Language Models](https://huggingface.co/course/chapter1/1)
